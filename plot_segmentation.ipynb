{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and constants\n",
    "import os\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import nilearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import scipy\n",
    "from tensorflow import keras\n",
    "# from keras import Sequential\n",
    "# from keras.layers import Dense, Flatten, Dropout, Reshape, Conv3D, Conv2D, Activation, UpSampling3D, \\\n",
    "#                          MaxPooling3D, SpatialDropout3D, BatchNormalization, Conv3DTranspose\n",
    "# from keras.layers.merge import concatenate\n",
    "# from keras.engine import Input, Model\n",
    "# from keras.optimizers import Adam\n",
    "# from keras import backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from nilearn import image\n",
    "from datetime import datetime\n",
    "from scipy import ndimage\n",
    "# import keras_unet\n",
    "import imageio\n",
    "\n",
    "\n",
    "DEBUG = False # for testing purposes\n",
    "DEBUG_SAMPLES = 80\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "TRAINING_DATA_ROOT_DIR = \"data/\"\n",
    "TRAIN_DIRS = [\"train/LGG\", \"train/HGG\"]\n",
    "VAL_DIRS = [\"val/val\"]\n",
    "\n",
    "SEQUENCES = [\"t1ce\"]\n",
    "GROUND_TRUTH_FILE = \"seg\"\n",
    "\n",
    "TYPE_OF_SEGMENTATION = \"ET\"\n",
    "\n",
    "N_X = 240\n",
    "N_Y = 240\n",
    "N_Z = 155\n",
    "NUM_CHANNELS = len(SEQUENCES)\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "\n",
    "PATCH_X = 80\n",
    "PATCH_Y = 80\n",
    "PATCH_Z = 80\n",
    "\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "PERCENTILE_95 = 10.204082 * 2 # 20 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d8bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_tc_seg  = nib.load('Brats18_TCIA03_288_1/Brats18_TCIA03_288_1_tc_t1ce_seg.nii.gz').get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_et_seg  = nib.load('Brats18_TCIA03_288_1/Brats18_TCIA03_288_1_et_t1ce_seg.nii.gz').get_fdata()\n",
    "\n",
    "for i in range(240):\n",
    "    for j in range(240):\n",
    "        for k in range(155):\n",
    "            if nii_img_et_seg[i][j][k] == 4:\n",
    "                nii_img_et_seg[i][j][k] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf632b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_orig_t1ce  = nib.load('Brats18_TCIA03_288_1/Brats18_TCIA03_288_1_t1ce.nii.gz').get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93865539",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_orig_flair  = nib.load('Brats18_TCIA03_288_1/Brats18_TCIA03_288_1_flair.nii.gz').get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e20c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_img = nib.load('../image-segmentation/data/val/val/Brats18_TCIA03_288_1/Brats18_TCIA03_288_1_t2.nii.gz').get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4083c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(orig_img[:, :, 65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb9b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_tc_seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f359576",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_orig_flair.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dd12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(nii_img_tc_seg[:, :, 65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b4567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nii_img_et_seg[:, :, 65], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(nii_img_orig_t1ce[:, :, 65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf170889",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_mask = np.zeros((240, 240, 4))\n",
    "\n",
    "for i in range(240):\n",
    "    for j in range(240):\n",
    "        combined_mask[i][j] = (0, 0, 0, 0)\n",
    "        if nii_img_tc_seg[i][j][65] == 1 and nii_img_et_seg[i][j][65] == 1:\n",
    "            combined_mask[i][j] = (0.9,0.1,0.1, 0.9)\n",
    "            continue\n",
    "        if nii_img_tc_seg[i][j][65] == 1 and nii_img_et_seg[i][j][65] == 0:\n",
    "            combined_mask[i][j] = (0.999,0.999, 0.999, 0.999)\n",
    "            continue\n",
    "#         if nii_img_tc_seg[i][j][65] == 0 and nii_img_et_seg[i][j][65] == 1:\n",
    "#             combined_mask[i][j] = (0, 255, 0, 0.75)\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd05ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(combined_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd2db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "nii_img_orig_t1ce  = nib.load('Brats18_TCIA03_288_1/Brats18_TCIA03_288_1_t1ce.nii.gz').get_fdata()\n",
    "\n",
    "combined = nii_img_orig_t1ce[:, :, 65]\n",
    "\n",
    "# k = 65\n",
    "\n",
    "# for i in range(240):\n",
    "#     for j in range(240):\n",
    "# #         pass\n",
    "# #         combined[i][j] = 0\n",
    "#         if nii_img_tc_seg[i][j][k] != 0 and nii_img_et_seg[i][j][k] != 0:\n",
    "#             combined[i][j] = 100\n",
    "# #             print(1, i, j)\n",
    "#             continue\n",
    "#         if nii_img_tc_seg[i][j][k] != 0 and nii_img_et_seg[i][j][k] == 0:\n",
    "#             combined[i][j] = 100\n",
    "# #             print(2, i, j)\n",
    "#             continue\n",
    "#         if nii_img_tc_seg[i][j][k] == 0 and nii_img_et_seg[i][j][k] != 0:\n",
    "#             combined[i][j] = 100\n",
    "# #             print(3, i, j)\n",
    "#             continue\n",
    "\n",
    "plt.imshow(combined)\n",
    "# plt.imshow(nii_img_tc_seg[:, :, 65], cmap='jet', alpha=0.25)\n",
    "# plt.imshow(nii_img_et_seg[:, :, 65], cmap='jet', alpha=0.25)\n",
    "plt.imshow(combined_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(combined_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67624c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
